{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:a0483178-c30e-4fdd-b2c2-349e130ab260.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But today, we can do exactly that, in just a few minutes, using entirely free resources!\n",
    "\n",
    "The basic steps we'll take are:\n",
    "\n",
    "1. Use DuckDuckGo to search for images of \"bird photos\"\n",
    "1. Use DuckDuckGo to search for images of \"forest photos\"\n",
    "1. Fine-tune a pretrained neural network to recognise these two groups\n",
    "1. Try running this model on a picture of a bird and see if it works."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download images of birds and non-birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import ddg_images\n",
    "from fastcore.all import *\n",
    "\n",
    "def search_images(term, max_images=30):\n",
    "    print(f\"Searching for '{term}'\")\n",
    "    return L(ddg_images(term, max_results=max_images)).itemgot('image')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by searching for a bird photo and seeing what kind of result we get. We'll start by getting URLs from a search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB: `search_images` depends on duckduckgo.com, which doesn't always return correct responses.\n",
    "#    If you get a JSON error, just try running it again (it may take a couple of tries).\n",
    "urls = search_images('bird photos', max_images=1)\n",
    "urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastdownload import download_url\n",
    "dest = 'bird.jpg'\n",
    "download_url(urls[0], dest, show_progress=False)\n",
    "\n",
    "from fastai.vision.all import *\n",
    "im = Image.open(dest)\n",
    "im.to_thumb(256,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets do the same with forest photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url(search_images('forest photos', max_images=1)[0], 'forest.jpg', show_progress=False)\n",
    "Image.open('forest.jpg').to_thumb(256,256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our searches seem to be giving reasonable results, so let's grab a few examples of each of \"bird\" and \"forest\" photos, and save each group of photos to a different folder (I'm also trying to grab a range of lighting conditions here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searches = 'forest', 'bird'\n",
    "path = Path('bird_or_not')\n",
    "\n",
    "for o in searches:\n",
    "    dest = (path/o)\n",
    "    dest.mkdir(exist_ok=True, parents=True)\n",
    "    download_images(dest, urls=search_images(f' {o} photo'))    #   from fastai does this in parallel\n",
    "    resize_images(path/o, max_size=400, dest=path/o)            #   resizing for faster since it is much faster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  training our model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some photos might not download correctly which could cause our model training to fail, so we'll remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   returns the number of failed to download photos\n",
    "failed = verify_images(get_image_files(path))\n",
    "failed.map(Path.unlink)\n",
    "len(failed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, we'll need `DataLoaders`, which is an object that contains a *training set* (the images used to create a model) and a *validation set* (the images used to check the accuracy of a model -- not used during training). In `fastai` we can create that easily using a `DataBlock`, and view sample images from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataBlock(\n",
    "    blocks = (ImageBlock, CategoryBlock),\n",
    "    get_items = get_image_files,\n",
    "    splitter = RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y = parent_label,\n",
    "    item_tfms = [Resize(192, method='squish')]\n",
    ").dataloaders(path)\n",
    "\n",
    "dls.show_batch(max_n=6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here what each of the `DataBlock` parameters means:\n",
    "\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "\n",
    "The inputs to our model are images, and the outputs are categories (in this case, \"bird\" or \"forest\").\n",
    "\n",
    "    get_items=get_image_files, \n",
    "\n",
    "To find all the inputs to our model, run the `get_image_files` function (which returns a list of all image files in a path).\n",
    "\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "\n",
    "Split the data into training and validation sets randomly, using 20% of the data for the validation set.\n",
    "\n",
    "    get_y=parent_label,\n",
    "\n",
    "The labels (`y` values) is the name of the `parent` of each file (i.e. the name of the folder they're in, which will be *bird* or *forest*).\n",
    "\n",
    "    item_tfms=[Resize(192, method='squish')]\n",
    "\n",
    "Before training, resize each image to 192x192 pixels by \"squishing\" it (as opposed to cropping it)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to train our model. The fastest widely used computer vision model is `resnet18`. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds...)\n",
    "\n",
    "`fastai` comes with a helpful `fine_tune()` method which automatically uses best practices for fine tuning a pre-trained model, so we'll use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_bird,_,probs = learn.predict(PILImage.create('bird.jpg'))\n",
    "print(f\"this is a : {is_bird}.\")\n",
    "print(f\"probability its a bird: {probs[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
